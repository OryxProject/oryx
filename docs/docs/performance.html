
<!DOCTYPE html>
<!--
 Generated by Apache Maven Doxia at 2017-09-06
 Rendered using Reflow Maven Skin 1.1.1 (http://andriusvelykis.github.io/reflow-maven-skin)
-->
<html  xml:lang="en" lang="en">

	<head>
		<meta charset="UTF-8" />
		<title>Oryx &#x2013; Performance</title>
		<meta name="viewport" content="width=device-width, initial-scale=1.0" />
		<meta name="description" content="" />
		<meta http-equiv="content-language" content="en" />

		<link href="http://netdna.bootstrapcdn.com/bootswatch/2.3.2/united/bootstrap.min.css" rel="stylesheet" />
		<link href="http://netdna.bootstrapcdn.com/twitter-bootstrap/2.3.1/css/bootstrap-responsive.min.css" rel="stylesheet" />
		<link href="../css/bootswatch.css" rel="stylesheet" />
		<link href="../css/reflow-skin.css" rel="stylesheet" />


		<link href="../css/lightbox.css" rel="stylesheet" />

		<link href="../css/site.css" rel="stylesheet" />
		<link href="../css/print.css" rel="stylesheet" media="print" />

		<!-- Le HTML5 shim, for IE6-8 support of HTML5 elements -->
		<!--[if lt IE 9]>
			<script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
		<![endif]-->



	</head>

	<body class="page-docs-performance project-oryx" data-spy="scroll" data-offset="60" data-target="#toc-scroll-target">

		<div class="navbar navbar-fixed-top">
			<div class="navbar-inner">
				<div class="container">
					<a class="btn btn-navbar" data-toggle="collapse" data-target="#top-nav-collapse">
						<span class="icon-bar"></span>
						<span class="icon-bar"></span>
						<span class="icon-bar"></span>
					</a>
					<a class="brand" href="../index.html">Oryx 2</a>
					<div class="nav-collapse collapse" id="top-nav-collapse">
						<ul class="nav pull-right">
							<li ><a href="../index.html" title="Overview">Overview</a></li>
							<li ><a href="endusers.html" title="Docs: End Users">Docs: End Users</a></li>
							<li ><a href="developer.html" title="Docs: Dev">Docs: Dev</a></li>
							<li ><a href="admin.html" title="Docs: Admin">Docs: Admin</a></li>
							<li class="active"><a href="" title="Performance">Performance</a></li>
							<li ><a href="../apidocs/index.html" title="Javadoc">Javadoc</a></li>
							<li ><a href="https://github.com/OryxProject/oryx" title="GitHub" class="externalLink">GitHub</a></li>
							<li ><a href="https://github.com/OryxProject/oryx/releases" title="Download" class="externalLink">Download</a></li>
						</ul>
					</div><!--/.nav-collapse -->
				</div>
			</div>
		</div>

	<div class="container">

	<!-- Masthead
	================================================== -->

	<header>
	</header>

	<div class="main-body">
	<div class="row">
		<div class="span8">
			<div class="body-content">
<p>This collects assorted comments, rules of thumb, and benchmarks related to performance: how much resource various things take to do various amounts of work.</p> 
<div class="page-header">
 <h1 id="hardware_and_cluster_design">Hardware and Cluster Design</h1>
</div> 
<p>In general there are no special hardware or cluster requirements. The cluster resource requirements will be driven primarily by Spark-based jobs, which tend to be memory-intensive and occasionally CPU-intensive, but not generally I/O-bound. If data ingest rate is <i>very</i> high, Kafka may need some special consideration. In both cases, there is nothing different about sizing these from any other Kafka / Spark job.</p> 
<h1 id="data_transport">Data Transport</h1> 
<p>Since Kafka is the underlying data transport, the storage require to ingest and store messages is just that of Kafka. See <a class="externalLink" href="https://kafka.apache.org/performance.html">Kafka performance</a> figures for information. In general, Kafka is not nearly a bottleneck and can be sized like any other usage of Kafka.</p> 
<h1 id="native_blas_acceleration">Native BLAS Acceleration</h1> 
<p>Note that some parts of Spark and Oryx can use a native implementation of <a class="externalLink" href="http://www.netlib.org/blas/">BLAS</a>, a linear algebra library, to accelerate some operations. This integration is enabled by a library called <a class="externalLink" href="https://github.com/fommil/netlib-java"><tt>netlib-java</tt></a>. </p> 
<p>Because some dependencies of <tt>netlib-java</tt> are licensed under an open source license that is materially different from this project’s license (GPL, instead of Apache License 2.0), this support is not built in to the Oryx distribution.</p> 
<p>It can be enabled however by building Oryx with the <tt>-Pnetlib</tt> flag. </p> 
<p>If using a standard distribution of Oryx that’s not built this way, it can also be enabled by building the support into your application. To do so, add this dependency to your application’s <tt>pom.xml</tt> file, where <tt>netlib.java.version</tt> matches the one specified by Oryx and Spark:</p> 
<div class="source"> 
 <div class="source"> 
  <pre>&lt;dependency&gt;
  &lt;groupId&gt;com.github.fommil.netlib&lt;/groupId&gt;
  &lt;artifactId&gt;all&lt;/artifactId&gt;
  &lt;version&gt;${netlib.java.version}&lt;/version&gt;
  &lt;type&gt;pom&lt;/type&gt;
&lt;/dependency&gt;
</pre> 
 </div> 
</div> 
<h1 id="batch_layer">&nbsp;Batch Layer</h1> 
<p>The Batch Layer’s particular role is model building, and the element that is of most interest to benchmark are likely the model building processes implemented in the app tier, on top of MLlib. Here again, the resources required to build a model over a certain amount of data are just that of the underlying MLlib implementations of ALS, k-means and decision forests.</p> 
<p>Any performance tuning or benchmarks for MLlib will be valid for the Batch Layer’s pre-made implementations on MLlib, and there is nothing different to know for Oryx.</p> 
<div class="section"> 
 <h2 id="JVM_Tuning">JVM Tuning</h2> 
 <p>Choosing the number of Spark executors, cores and memory is a topic in its own right.</p> 
 <p>More executors means, naturally, more cores and memory. The number should not exceed the number of machines in the cluster; it can be less. See <tt>oryx.batch.streaming.num-executors</tt>.</p> 
 <p>More cores means potentially more parallel processing. You can observe the number of tasks and thus inherent parallelism in the Spark UI of a Batch layer run. Beyond this count, more cores doesn’t add parallelism. Fewer is OK and simply increases the run time. Of course, enough cores should be available to get the batch process completed comfortably within the batch interval. The number of cores is configured by <tt>oryx.batch.streaming.executor-cores</tt>.</p> 
 <p>If your jobs are running out of memory, the driver or executors may need more memory. More memory may be helpful if you notice in the “Storage” tab of your batch layer that some cached RDDs show as less than 100% cached. See <tt>oryx.batch.streaming.executor-memory</tt>.</p> 
 <p>The <tt>--jvm-args</tt> flag to <tt>oryx-run.sh</tt> can be used to set JVM memory parameters for all JVM processes. For example, <tt>-XX:+UseG1GC</tt> is a good default garbage collection setting.</p> 
 <h1 id="serving_layer">Serving Layer</h1> 
 <p>The REST API is powered by Tomcat. Its configuration is not exposed to the user, but is already reasonably tuned internally for its workload. The Tomcat container itself introduces little overhead and is not a concern for performance. </p> 
 <p>What is likely of interest is performance of CPU-intensive app tier implementations provided in the project, rather than the framework itself.</p> 
</div> 
<div class="section"> 
 <h2 id="aBenchmark_Alternating_Least_Squares_Recommendation">&nbsp;Benchmark: Alternating Least Squares Recommendation</h2> 
 <p>Since most operations in the ALS app Serving Layer are performed on a huge matrix in memory in real-time, this app is the most challenging to scale. General rules of thumb follow below.</p> 
 <p>To run similar benchmarks, use <tt>LoadBenchmark</tt>, which has some configuration parameters:</p> 
 <div class="source"> 
  <div class="source"> 
   <pre>mvn -DskipTests -Pnetlib clean install
mvn -Pbenchmark -Pnetlib \
 -Doryx.test.als.benchmark.users=1000000 \
 -Doryx.test.als.benchmark.items=5000000 \
 -Doryx.test.als.benchmark.features=250 \
 -Doryx.test.als.benchmark.lshSampleRate=0.3 \
 -Doryx.test.als.benchmark.workers=2 \
 integration-test \
 -pl app/oryx-app-serving
</pre> 
  </div> 
 </div> 
 <div class="section"> 
  <h3 id="aMemory">&nbsp;Memory</h3> 
  <ul> 
   <li>Memory requirements scale linearly with (users + items) x features</li> 
   <li>GC settings like <tt>-XX:+UseStringDeduplication</tt> help a lot (reflected below)</li> 
   <li>At scale, 1M users or items ~= 500-1000M of heap required, depending on features</li> 
  </ul> 
  <p>Example steady-state heap usage:</p> 
  <table border="0" class="bodyTable table table-striped table-hover"> 
   <thead> 
    <tr class="a"> 
     <th align="right">Features </th> 
     <th align="right">Users+Items (M) </th> 
     <th align="right">Heap (MB) </th> 
    </tr> 
   </thead> 
   <tbody> 
    <tr class="b"> 
     <td align="right">50 </td> 
     <td align="right">2 </td> 
     <td align="right">1400 </td> 
    </tr> 
    <tr class="a"> 
     <td align="right">50 </td> 
     <td align="right">6 </td> 
     <td align="right">2600 </td> 
    </tr> 
    <tr class="b"> 
     <td align="right">50 </td> 
     <td align="right">21 </td> 
     <td align="right">7500 </td> 
    </tr> 
    <tr class="a"> 
     <td align="right">250 </td> 
     <td align="right">2 </td> 
     <td align="right">3000 </td> 
    </tr> 
    <tr class="b"> 
     <td align="right">250 </td> 
     <td align="right">6 </td> 
     <td align="right">7500 </td> 
    </tr> 
    <tr class="a"> 
     <td align="right">250 </td> 
     <td align="right">21 </td> 
     <td align="right">25800 </td> 
    </tr> 
   </tbody> 
  </table> 
 </div> 
 <div class="section"> 
  <h3 id="Request_Latency_Throughput">Request Latency, Throughput</h3> 
  <ul> 
   <li>Recommend and similarity computation time scales linearly with items x features</li> 
   <li>A single request is parallelized across CPUs; max throughput and minimum latency is already achieved at about 1-2 concurrent requests</li> 
   <li>Locality sensitive hashing decreases processing time roughly linearly; 0.33 ~= 1/0.33 ~= 3x faster (setting too low adversely affects result quality)</li> 
  </ul> 
  <p>Below are representative throughput / latency measurements for the <tt>/recommend</tt> endpoint using<br />a 32-core Intel Xeon 2.3GHz (Haswell), OpenJDK 8 and flags <tt>-XX:+UseG1GC -XX:NewRatio=9 -XX:+UseStringDeduplication</tt>. Heap size was comfortably large enough for the data set in each case. The tests were run with 1-3 concurrent request at a time, as necessary to achieve near-full CPU utilization.</p> 
  <p><i>With LSH (sample rate = 0.3)</i></p> 
  <table border="0" class="bodyTable table table-striped table-hover"> 
   <thead> 
    <tr class="a"> 
     <th align="right">Features </th> 
     <th align="right">Items (M) </th> 
     <th align="right">Throughput (qps) </th> 
     <th align="right">Latency (ms) </th> 
    </tr> 
   </thead> 
   <tbody> 
    <tr class="b"> 
     <td align="right">50 </td> 
     <td align="right">1 </td> 
     <td align="right">437 </td> 
     <td align="right">7 </td> 
    </tr> 
    <tr class="a"> 
     <td align="right">250 </td> 
     <td align="right">1 </td> 
     <td align="right">160 </td> 
     <td align="right">12 </td> 
    </tr> 
    <tr class="b"> 
     <td align="right">50 </td> 
     <td align="right">5 </td> 
     <td align="right">91 </td> 
     <td align="right">21 </td> 
    </tr> 
    <tr class="a"> 
     <td align="right">250 </td> 
     <td align="right">5 </td> 
     <td align="right">37 </td> 
     <td align="right">54 </td> 
    </tr> 
    <tr class="b"> 
     <td align="right">50 </td> 
     <td align="right">20 </td> 
     <td align="right">25 </td> 
     <td align="right">79 </td> 
    </tr> 
    <tr class="a"> 
     <td align="right">250 </td> 
     <td align="right">20 </td> 
     <td align="right">7 </td> 
     <td align="right">134 </td> 
    </tr> 
   </tbody> 
  </table> 
  <p><i>Without LSH (sample rate = 1.0)</i></p> 
  <table border="0" class="bodyTable table table-striped table-hover"> 
   <thead> 
    <tr class="a"> 
     <th align="right">Features </th> 
     <th align="right">Items (M) </th> 
     <th align="right">Throughput (qps) </th> 
     <th align="right">Latency (ms) </th> 
    </tr> 
   </thead> 
   <tbody> 
    <tr class="b"> 
     <td align="right">50 </td> 
     <td align="right">1 </td> 
     <td align="right">70 </td> 
     <td align="right">28 </td> 
    </tr> 
    <tr class="a"> 
     <td align="right">250 </td> 
     <td align="right">1 </td> 
     <td align="right">24 </td> 
     <td align="right">40 </td> 
    </tr> 
    <tr class="b"> 
     <td align="right">50 </td> 
     <td align="right">5 </td> 
     <td align="right">16 </td> 
     <td align="right">57 </td> 
    </tr> 
    <tr class="a"> 
     <td align="right">250 </td> 
     <td align="right">5 </td> 
     <td align="right">6 </td> 
     <td align="right">181 </td> 
    </tr> 
    <tr class="b"> 
     <td align="right">50 </td> 
     <td align="right">20 </td> 
     <td align="right">4 </td> 
     <td align="right">257 </td> 
    </tr> 
    <tr class="a"> 
     <td align="right">250 </td> 
     <td align="right">20 </td> 
     <td align="right">1 </td> 
     <td align="right">668 </td> 
    </tr> 
   </tbody> 
  </table> 
 </div> 
</div> 
<div class="section"> 
 <h2 id="JVM_Tuning">JVM Tuning</h2> 
 <p>Running the Serving layer(s) on machines with more available cores generally means more requests can be served in parallel. In the case of ALS, some requests like <tt>/recommend</tt> can use multiple cores in one request.</p> 
 <p>Memory requirements are dominated by the need to load a model in memory. For large models like ALS this may mean ensuring that the Serving layer memory setting is comfortably high enough to hold the model without GC thrashing. See <tt>oryx.serving.memory</tt>.</p> 
 <p><tt>-XX:NewRatio=9</tt> (or values thereabout) devote much more of the heap to storing long-lived objects that don’t need garbage collection much. This is true of serving layers holding mostly large, long-lived data structures. <tt>-XX:+UseG1GC</tt> remains a good garbage collection setting to supply with <tt>--jvm-args</tt>.<br /><tt>-XX:+UseStringDeduplication</tt> can reduce memory requirements by about 20%.</p> 
 <h1 id="speed_layer">Speed Layer</h1> 
 <p>The Speed layer <i>driver</i> process is as memory-hungry as the Serving layer since it also loads a model into memory. The memory of the driver process, controlled by <tt>oryx.speed.streaming.driver-memory</tt>, may need to be set like the Serving layer memory, and may benefit from the same JVM flags.</p> 
 <p>It is also a Spark Streaming job and so needs executors configures like the Batch layer. However, there is generally much less processing done by the Speed layer’s executors, but at a much lower latency requirement.</p> 
 <p>Executors will have to be sized to consume input Kafka partitions fully in parallel; the number of cores times number of executors should be at least the number of Kafka partitions.</p> 
</div>
			</div>
		</div>
		<div class="span4">
			<div id="toc-sidebar">
				<div class="well">
					<ul class="nav nav-list">
						<li class="nav-header">Table of Contents</li>
		<li><a href="#hardware_and_cluster_design" title="Hardware and Cluster Design">Hardware and Cluster Design</a>
		<li><a href="#data_transport" title="Data Transport">Data Transport</a>
		<li><a href="#native_blas_acceleration" title="Native BLAS Acceleration">Native BLAS Acceleration</a>
		<li class="dropdown"><a href="#batch_layer" title=" Batch Layer"> Batch Layer <b class="caret"></b></a>
			<ul class="nav nav-list">
		<li><a href="#JVM_Tuning" title="JVM Tuning">JVM Tuning</a>
				<li class="divider"></li>
			</ul>
		</li>
		<li class="dropdown"><a href="#serving_layer" title="Serving Layer">Serving Layer <b class="caret"></b></a>
			<ul class="nav nav-list">
		<li class="dropdown"><a href="#aBenchmark_Alternating_Least_Squares_Recommendation" title=" Benchmark: Alternating Least Squares Recommendation"> Benchmark: Alternating Least Squares Recommendation <b class="caret"></b></a>
			<ul class="nav nav-list">
		<li><a href="#aMemory" title=" Memory"> Memory</a>
		<li><a href="#Request_Latency_Throughput" title="Request Latency, Throughput">Request Latency, Throughput</a>
				<li class="divider"></li>
			</ul>
		</li>
		<li><a href="#JVM_Tuning" title="JVM Tuning">JVM Tuning</a>
				<li class="divider"></li>
			</ul>
		</li>
		<li><a href="#speed_layer" title="Speed Layer">Speed Layer</a>
					</ul>
				</div>
			</div>
		</div>
	</div>
	</div>

	</div><!-- /container -->

	<!-- Footer
	================================================== -->
	<footer class="well">
		<div class="container">
			<div class="row">
				<div class="span9 bottom-nav">
					<ul class="nav nav-list">
					</ul>
				</div>
			</div>
		</div>
	</footer>

	<div class="container subfooter">
		<div class="row">
			<div class="span12">
				<p class="pull-right"><a href="#">Back to top</a></p>
				<p class="copyright">Copyright &copy;2014-2017. All Rights Reserved.</p>
				<p><a href="http://github.com/andriusvelykis/reflow-maven-skin" title="Reflow Maven skin">Reflow Maven skin</a> by <a href="http://andrius.velykis.lt" target="_blank" title="Andrius Velykis">Andrius Velykis</a>.</p>
			</div>
		</div>
	</div>

	<!-- Le javascript
	================================================== -->
	<!-- Placed at the end of the document so the pages load faster -->
	<script src="http://ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>

	<script src="http://netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/js/bootstrap.min.js"></script>
	<script src="../js/lightbox.min.js"></script>
	<script src="../js/reflow-scroll.js"></script>

	<script src="../js/reflow-skin.js"></script>

	</body>
</html>
